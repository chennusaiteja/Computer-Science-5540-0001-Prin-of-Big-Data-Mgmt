# -*- coding: utf-8 -*-
"""WarmupProject_histogram.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1r9Dxr0wuGFOIJjQP_j0VZsu1rqkF5kPg

Importing pandas, ntlk(for stopwords)

Downloaded stopwords using nltk library
"""

import pandas as pd
import re
import pandas as pd
import csv
# !pip install nltk
import nltk
nltk.download('stopwords')

"""Mounting Google Drive 


"""

from google.colab import drive
drive.mount('/content/drive')

"""Reading the text file(nytimes_news_articles.txt) which is located in google drive path(/content/drive/MyDrive/Warm-up Project_Prin of Big Data Mgmt/nytimes_news_articles.txt)"""

csvfile = open("/content/drive/MyDrive/Warm-up Project_Prin of Big Data Mgmt/nytimes_news_articles.txt")
reader = csv.reader(csvfile, quoting=csv.QUOTE_NONE)
new_list=[]
count = 0
first_url = 0
current_doc=""
old_url =""
for lines_list in reader:
    for line in lines_list:
      if "URL: http://www.nytimes.com" in line:
        if first_url != 0 and '/us/politics/' not in old_url:  
          new_list.append(current_doc)
          current_doc = ""
        else:
          current_doc=""
        old_url = line
      elif line.strip():
        first_url = 1
        current_doc = current_doc + line

current_doc

"""Creating a list of data in column called doc_data"""

df_op = pd.DataFrame(new_list, columns=['doc_data'])

"""Storing all downloaded stop words in the variable stop """

import nltk
from nltk.corpus import stopwords
stop = stopwords.words('english')

"""Displaying all the stop words"""

stop

"""Removing stopwords from the list of data in the text file"""

df_op['without_stop_words'] = df_op['doc_data'].apply(lambda x: [item for item in x.split() if item not in stop])

df_op['count'] = df_op['without_stop_words'].apply(lambda x: len(x))

"""Displaying the first five rows with out stop words and the word count"""

df_op.head(5)

"""displaying the output of all articles data by removing stopwords"""

df_op

#plotting the histogram

hist= df_op.hist(column='count')
for ax in hist.flatten():
    ax.set_xlabel("articles")
    ax.set_ylabel("sizes")
    ax.set_title('Size of news articles')